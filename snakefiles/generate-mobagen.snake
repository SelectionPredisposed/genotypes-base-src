import os

# Runtime variables
include: "variables.py"

rule all:
    input:
        expand(config['output_base'] + 'imputed/all/{chr}.vcf.gz', chr=chromx),
        expand(config['output_base'] + 'imputed/all/{chr}.vcf.gz.tbi', chr=chromx),
        expand(config['output_base'] + 'genotyped/allbatch_genotyped/{chr}.vcf.gz', chr=chromx),
        expand(config['output_base'] + 'genotyped/allbatch_genotyped/merged/autosomes.{ext}', ext=['bed','bim','fam']),
        expand(config['output_base'] + 'genotyped/allbatch_genotyped/bedset/{chr}.{ext}', chr=chrom, ext=['bed','bim','fam']),
        expand(config['output_base'] + 'imputed/common-bedset/merge/allchr-imputed-common.{ext}', ext=['bed','bim','fam']),
        expand(os.path.join(config['output_base'], 'imputed', 'all', 'bgen', '{chr}.bgen'), chr=chromx),
        expand(os.path.join(config['output_base'], 'imputed', 'all', 'bgen', '{chr}.sample'), chr=chromx)

# merge full imputed VCFs: HARVEST, ROT1, ROT2, TED, NORMENT1 (FEB18, MAY16, JAN15, JUN15)
rule merge_vcf:
    input:
        harvest=config['harvest_base_imputed'] + "{chr}.vcf.gz",
        rot1=config['rot1_base_imputed'] + "{chr}.vcf.gz",
        rot2=config['rot2_base_imputed'] + "{chr}.vcf.gz",
        ted=config['ted_base_imputed'] + "{chr}.vcf.gz",
        feb18=config['feb18_base_imputed'] + "{chr}.vcf.gz",
        may16=config['may16_base_imputed'] + "{chr}.vcf.gz",
        jun15=config['jun15_base_imputed'] + "{chr}.vcf.gz",
        jan15=config['jan15_base_imputed'] + "{chr}.vcf.gz"
    output:
        vcf=config['output_base'] + 'imputed/all/{chr}.vcf.gz',
        tbi=config['output_base'] + 'imputed/all/{chr}.vcf.gz.tbi'
    params:
        bcftools=bcftools,
        mergefile=os.path.join(tmpdir,'{chr}-mergelist')
    shell:
        """
        # Make mergefile before merging per chromosome
        echo {input.harvest} > {params.mergefile}
        echo {input.rot1} >> {params.mergefile}
        echo {input.rot2} >> {params.mergefile}
        echo {input.ted} >> {params.mergefile}
        echo {input.feb18} >> {params.mergefile}
        echo {input.may16} >> {params.mergefile}
        echo {input.jun15} >> {params.mergefile}
        echo {input.jan15} >> {params.mergefile}

        {params.bcftools} merge --file-list {params.mergefile} --info-rules INFO:avg -o {output.vcf} -Oz
        tabix -f {output.vcf}
        """

# Convert vcf to bgen 1.2
rule vcf_to_bgen:
    input:
        vcf=config['output_base'] + 'imputed/all/{chr}.vcf.gz'
    output:
        bgen=os.path.join(config['output_base'], 'imputed', 'all', 'bgen', '{chr}.bgen'),
        sample=os.path.join(config['output_base'], 'imputed', 'all', 'bgen', '{chr}.sample')
    params:
        bgenprefix=os.path.join(config['output_base'], 'imputed', 'all', 'bgen', '{chr}')
    shell:
        """
        # Print header lines to comply with bgen sample file format
        #echo "ID_1 ID_2 missing sex phenotype" > {output.sample}
        #echo "0 0 0 D B" >> {output.sample}

        # Extract sample list from VCF
        #bcftools query -l {input.vcf} | awk '{{print $1, $1, "0","0","NA"}}' >> {output.sample}

        plink2 \
            --vcf {input.vcf} dosage=DS \
            --make-pgen erase-phase \
            --threads 30 \
            --out {tmpdir}/plinkout_unphased{wildcards.chr}

        plink2 \
            --pfile {tmpdir}/plinkout_unphased{wildcards.chr} \
            --export bgen-1.2 ref-first bits=8 id-delim='-' \
            --threads 30 \
            --out {params.bgenprefix}


        # Use QCTOOL v2 to convert vcf to bgen
        # -g input file
        # -og output bgen file
        # -bgen-bits BOLT-LMM requires 8 bit encoding
        # -s input sample file
        # -os output sample file (generated above in this rule)
        # -output-sample-format traditional (not used here) specifies traditional saple format (not json)
        #/home/oyvindhe/downloads/software/qctool-v2-src/qctool/build/default/qctool_v2.0.4 \
        #    -g {input.vcf} \
        #    -vcf-genotype-field GP \
        #    -ofiletype "bgen_v1.2" \
        #    -bgen-bits 8 \
        #    -threads 20 \
        #    -s {output.sample} \
        #    -og {output.bgen}
        """

# Convert vcf to dosage (BOLT-LMM format)
rule vcf_to_dosage:
    input:
        vcf=config['output_base'] + 'imputed/all/{chr}.vcf.gz'
    output:
        sample=os.path.join(config['output_base'], 'imputed', 'all', 'dosage', '{chr}.sample'),
        dosage=os.path.join(config['output_base'], 'imputed', 'all', 'dosage', '{chr}.dosage.gz')
    params:
    shell:
        """
        # Convert VCF to gzipped dosage format compatible with BOLT-LMM
        bcftools query -f '%ID %CHROM %POS %ALT %REF [ %DS ]' {input.vcf} | gzip > {output.dosage}
        
        # Output corresponding sample file
        bcftools query -l {input.vcf} > {output.sample}
        """

# merge common bedset: HARVEST with ROT1
rule merge_common_bedset:
    input:
        harvest=expand('/mnt/archive/HARVEST/genotypes-base/imputed/common-bedset/merge/allchr-imputed-common.{ext}', ext=['bed','bim','fam']),
        rot1=expand('/mnt/archive/ROTTERDAM1/genotypes-base/imputed/common-bedset/merge/allchr-imputed-common.{ext}', ext=['bed','bim','fam'])
    output:
        outbed=expand(config['output_base'] + 'imputed/common-bedset/merge/allchr-imputed-common.{ext}', ext=['bed','bim','fam'])
    params:
        inharvest='/mnt/archive/HARVEST/genotypes-base/imputed/common-bedset/merge/allchr-imputed-common',
        inrot1='/mnt/archive/ROTTERDAM1/genotypes-base/imputed/common-bedset/merge/allchr-imputed-common',
        outbed=config['output_base'] + 'imputed/common-bedset/merge/allchr-imputed-common',
        tmp=config['tmp_path']
    shell:
        """
        plink \
            --bfile {params.inharvest} \
            --bmerge {params.inrot1} \
            --merge-mode 4 \
            --out {params.tmp}triallelic || true

        plink \
            --bfile {params.inharvest} \
            --exclude {params.tmp}triallelic.missnp \
            --make-bed \
            --out {params.tmp}harvest_biallelic_only

        plink \
            --bfile {params.inrot1} \
            --exclude {params.tmp}triallelic.missnp \
            --make-bed \
            --out {params.tmp}rot1_biallelic_only
        
        plink \
            --bfile {params.tmp}harvest_biallelic_only \
            --bmerge {params.tmp}rot1_biallelic_only \
            --merge-mode 4 \
            --out {params.outbed}
        """


# remove samples with too high IBD across batches
# rule ibd_prune_core_offspring:
#     input:
#         harvest_core_offspring=config['core_offspring_harvest'],
#         rot1_core_offspring=config['core_offspring_rot1']
#     output:
#     params:
#     shell:
#         """
#         # Merge the core lists
#         cat {input.harvest_core_offspring} {input.rot1_core_offspring} > {tmp}
#         """

# filter out genotyped markers from merged set
# TYPED + INFO=1 equals all markers genotyped across batches
# TODO: Change this to use the slower BCFtools filtering instead. The grep approach
# does not output VCF standards compliant files
rule filter_genotyped:
    input:
        vcf=config['output_base'] + 'imputed/all/{chr}.vcf.gz',
        tbi=config['output_base'] + 'imputed/all/{chr}.vcf.gz.tbi'
    output:
        vcf=config['output_base'] + 'genotyped/allbatch_genotyped/{chr}.vcf.gz'
    params:
    shell:
        """
        # Get the header of the VCF
        # The || forces command to return true. Needed since command sends a 141 (sigpipe) error
        # due to open file handle (probably) - dirty hack to prevent having to wait for full read of file
        zcat {input.vcf} | head -n150 | grep "^#" | gzip > {output.vcf} || true

        # Filter markers with TYPED & INFO=1 in INFO field
        zcat {input.vcf} | grep -v "^#" | grep "TYPED" | gzip >> {output.vcf}
        
        """

# Convert VCFs into bedsets
rule vcf_to_bed:
    input:
        vcf=config['output_base'] + 'genotyped/allbatch_genotyped/{chr}.vcf.gz'
    output:
        expand(config['output_base'] + 'genotyped/allbatch_genotyped/bedset/{{chr}}.{ext}', ext=['bed','bim','fam'])
    params:
        out_stem=config['output_base'] + 'genotyped/allbatch_genotyped/bedset/{chr}'
    shell:
        """
        plink \
            --vcf {input.vcf} \
            --double-id \
            --make-bed \
            --out {params.out_stem}
        """

# generate filelist before merging bedsets
rule generate_merge_filelist:
    input:
        expand(config['output_base'] + 'genotyped/allbatch_genotyped/bedset/{chr}.{ext}', chr=chrom, ext=['bed','bim','fam'])
    output:
        config['tmp_path']  + 'filelist_merge'
    params:
        expand(config['output_base'] + 'genotyped/allbatch_genotyped/bedset/{chr}', chr=chrom)
    run:

        f = open(output[0], 'w')

        for item in params[0]:
            f.write("%s\n" % item)

# merge filtered vcfs
rule merge_bedsets:
    input:
        config['tmp_path'] + 'filelist_merge'
    output:
        expand(config['output_base'] + 'genotyped/allbatch_genotyped/merged/autosomes.{ext}', ext=['bed','bim','fam'])
    params:
        outstem=config['output_base'] + 'genotyped/allbatch_genotyped/merged/autosomes'
    shell:
        """
        plink --merge-list {input} --merge-mode 4 --out {params.outstem}
        """
